{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be easily seen how PCA retains information and use it classify with almost the same amount of accuracy. Following is an example to show it. (Example complied from the book 'Python for Data Science for Dummies' and scikit-learn website )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Olivetti faces dataset.\n",
      "\n",
      "The original database was available from\n",
      "\n",
      "    http://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html\n",
      "\n",
      "The version retrieved here comes in MATLAB format from the personal\n",
      "web page of Sam Roweis:\n",
      "\n",
      "    http://www.cs.nyu.edu/~roweis/\n",
      "\n",
      "There are ten different images of each of 40 distinct subjects. For some\n",
      "subjects, the images were taken at different times, varying the lighting,\n",
      "facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "details (glasses / no glasses). All the images were taken against a dark\n",
      "homogeneous background with the subjects in an upright, frontal position (with\n",
      "tolerance for some side movement).\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the Roweis version\n",
      "consists of 64x64 images.\n",
      "\n",
      "X values shape:  (400, 4096)\n",
      "Y values shape:  (400,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "dataset = fetch_olivetti_faces(shuffle=True, random_state=101)\n",
    "print dataset.DESCR\n",
    "print 'X values shape: ', dataset.data.shape\n",
    "print 'Y values shape: ',  dataset.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not let us experiment with number of components for PCA and see how much information we could retain with how many component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by 100 components: 0.935\n"
     ]
    }
   ],
   "source": [
    "n_components = 100\n",
    "rpca = PCA(n_components=n_components, whiten=True, random_state=101).fit(dataset.data)\n",
    "print 'Explained variance by %i components: %0.3f' % (n_components, np.sum(rpca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the previous run, we can retain about 87% information from the original dataset after projection with just 50 dimensions or features. The original dataset had 64 * 64 or 4096 features. This is already a significant improvement. When we split the train and test sets, this is even more evident where a smaller dataset for the training let's us keep more information with much less number of components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by 100 componnets: 0.942\n"
     ]
    }
   ],
   "source": [
    "n_components = 100\n",
    "xtr, xtst, ytr, ytst = train_test_split(dataset.data, dataset.target)\n",
    "rpca = PCA(n_components=n_components, whiten=True, random_state=103).fit(xtr)\n",
    "print 'Explained variance by %i componnets: %0.3f' % (n_components, np.sum(rpca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would see how SVM performs on this dataset with much smaller dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1).fit(xtr, ytr)\n",
    "print accuracy_score(ytst, clf.predict(xtst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us transform our training and testing dataset using PCA components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "cmp_xtr = rpca.transform(xtr)\n",
    "cmp_xtst = rpca.transform(xtst)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1).fit(cmp_xtr, ytr)\n",
    "print accuracy_score(ytst, clf.predict(cmp_xtst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it still retains almost the same classification accuracy as the original dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
